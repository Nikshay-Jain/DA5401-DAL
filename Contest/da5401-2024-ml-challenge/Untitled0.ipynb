{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ij2AMdp9X4cm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jHFYEw4VYAc8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sYrkDKWMYPES"
   },
   "outputs": [],
   "source": [
    "# array1 = np.load('/content/drive/MyDrive/dal_endsem/embeddings_1.npy')\n",
    "# array2 = np.load('/content/drive/MyDrive/dal_endsem/embeddings_2.npy')\n",
    "# X_train = np.concatenate((array1, array2))\n",
    "# X_test = np.load('/content/drive/MyDrive/dal_endsem/test_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.load('embeddings_1.npy')\n",
    "array2 = np.load('embeddings_2.npy')\n",
    "X_train = np.concatenate((array1, array2))\n",
    "X_test = np.load('test_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZltXbzZJYRft"
   },
   "outputs": [],
   "source": [
    "def parse_label_file(filename, delimiter=';'):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        labels.append(line.strip().split(delimiter))\n",
    "\n",
    "    return labels\n",
    "\n",
    "def create_label_to_index(labels):\n",
    "  unique_labels = set(labels)\n",
    "  label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
    "  return label_to_index\n",
    "\n",
    "def to_multi_hot(labels, label_to_index):\n",
    "  vocab_size = len(label_to_index)\n",
    "  multi_hot = np.zeros(vocab_size)\n",
    "\n",
    "  for label in labels:\n",
    "    index = label_to_index[label]\n",
    "    multi_hot[index] = 1\n",
    "\n",
    "  return multi_hot\n",
    "\n",
    "labelsfile1 = \"icd_codes_1.txt\"\n",
    "labels1 = parse_label_file(labelsfile1)\n",
    "labelsfile2 = \"icd_codes_2.txt\"\n",
    "labels2 = parse_label_file(labelsfile2)\n",
    "labels = labels1 + labels2\n",
    "\n",
    "all_labels = []\n",
    "for label in labels:\n",
    "    all_labels += label\n",
    "label_to_index = create_label_to_index(all_labels)\n",
    "\n",
    "multi_hot = []\n",
    "for label in labels:\n",
    "    multi_hot.append(to_multi_hot(label, label_to_index))\n",
    "\n",
    "y_train = np.array(multi_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1denHtAitpv"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(1024, activation='relu', input_dim=1024),\n",
    "    Dense(2048, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1400, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6)\n",
    "\n",
    "# Reduce batch size for less memory usage\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2,\n",
    "                    callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Model Loss over Epochs\")\n",
    "plt.show()\n",
    "\n",
    "# Predict the labels\n",
    "y_pred_prob = model.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_prob > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3JJ1uqnBYWl5"
   },
   "outputs": [],
   "source": [
    "#Write Outputfile\n",
    "################\n",
    "\n",
    "def create_index_to_label(label_to_index):\n",
    "  index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "  return index_to_label\n",
    "\n",
    "index_to_label = create_index_to_label(label_to_index)\n",
    "\n",
    "def create_txt_file(y_pred, index_to_label, filename=\"predicts.csv\"):\n",
    "\n",
    "  with open(filename, 'w') as f:\n",
    "    f.write(\"id,labels\\n\")\n",
    "    for i, prediction in enumerate(y_pred):\n",
    "      labels = []\n",
    "      for j, value in enumerate(prediction):\n",
    "        if value == 1:\n",
    "          labels.append(index_to_label[j])\n",
    "      labels = sorted(labels)\n",
    "      f.write(f\"{i+1},{';'.join(labels)}\\n\")\n",
    "\n",
    "create_txt_file(y_pred, index_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zstLw4J3dzyV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
